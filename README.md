# ğŸ“š AnÃ¡lise de Texto com Processamento de Linguagem Natural (PLN)

## âœ¨ IntroduÃ§Ã£o
Este projeto realiza a anÃ¡lise de um livro em domÃ­nio pÃºblico (*A Moreninha*, de Joaquim Manuel de Macedo) para estudar a diversidade de palavras e a frequÃªncia das palavras mais usadas. Utilizamos Python e bibliotecas de Processamento de Linguagem Natural (PLN) para:

- Extrair texto de um PDF ğŸ“
- Limpar e preprocessar o texto ğŸŒ
- Contar palavras totais e Ãºnicas âœ”ï¸
- Gerar um **grÃ¡fico de palavras mais frequentes** ğŸ“Š

## ğŸ‘¨â€ğŸ’» Tecnologias Utilizadas
- Python 3.x
- **NLTK**: Para tratamento de stopwords
- **PyPDF2**: Para extraÃ§Ã£o de texto do PDF
- **Matplotlib** e **NumPy**: Para visualizaÃ§Ã£o de dados
- ExpressÃµes Regulares (**re**): Para limpeza do texto

## âš¡ Como Rodar o Projeto
1. Clone o repositÃ³rio:
   ```sh
   git clone https://github.com/AugustoBuin/nlp-exercises-tc1_1.git
   cd nlp-exercises-tc1_1\src
   ```
2. Instale as dependÃªncias:
   ```sh
   pip install -r requirements.txt
   ```
3. Execute o script:
   ```sh
   python index.py
   ```

## ğŸ“ ExplicaÃ§Ã£o do CÃ³digo
1. **Extrai o texto do PDF** usando a biblioteca `PyPDF2`.
2. **Limpa o texto** removendo nÃºmeros, pontuaÃ§Ã£o e deixando tudo em minÃºsculas.
3. **Remove stopwords** (palavras comuns como "de", "o", "a") usando o `nltk`.
4. **Conta as palavras mais frequentes** e exibe as 25 mais usadas.
5. **Gera um grÃ¡fico de barras** mostrando a distribuiÃ§Ã£o das palavras.

## ğŸ“Š Exemplo de SaÃ­da
### Top 5 Palavras Mais Frequentes (Sem Stopwords)
```
1. augusto: 320
2. fabrÃ­cio: 250
3. moreninha: 180
4. amor: 160
5. joaninha: 140
```

### ğŸ¨ GrÃ¡fico Gerado
![GrÃ¡fico de FrequÃªncia](src/tc1-1.png)

## ğŸ¯ PossÃ­veis Melhorias
- Usar **WordCloud** para gerar uma nuvem de palavras.
- Implementar **lemmatization** para agrupar palavras com o mesmo radical.
- Aplicar **classificaÃ§Ã£o de sentimentos** no texto.

---
ğŸ›  Criado por [AugustoBuin](https://github.com/AugustoBuin) | 03/2025

